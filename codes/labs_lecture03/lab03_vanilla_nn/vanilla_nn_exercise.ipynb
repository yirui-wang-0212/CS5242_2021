{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"vanilla_nn_exercise.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"c3HULQ-5N8TG"},"source":["# Lab 03 : Vanilla neural networks -- exercise\n","\n","# Creating a one-layer network"]},{"cell_type":"code","metadata":{"id":"_ujjHuyjN8TT","executionInfo":{"status":"ok","timestamp":1630078272437,"user_tz":-480,"elapsed":3893,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}}},"source":["import torch\n","import torch.nn as nn"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQD6yuBHN8TW"},"source":["### Make a class for a one layer network. Let's call the layer \"mylayer\". And let's give it a bias."]},{"cell_type":"code","metadata":{"id":"X82U0VL8N8TX","executionInfo":{"status":"ok","timestamp":1630078272438,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}}},"source":["class one_layer_net(nn.Module):\n","\n","    def __init__(self,  input_size, output_size  ):\n","        super(one_layer_net , self).__init__()\n","        \n","        # complete here\n","        self.mylayer = nn.Linear(input_size, output_size)\n","        \n","    def forward(self, x):\n","        \n","        # complete here\n","        # complete here\n","        s = self.mylayer(x)\n","        \n","        p = torch.softmax(s, dim = 0)\n","        \n","        return p"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_0XvMHxoN8TZ"},"source":["### Create an instance of a one layer net that take input of size 2 and return output of size 2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRrfxbuON8Tb","executionInfo":{"status":"ok","timestamp":1630078331824,"user_tz":-480,"elapsed":351,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"decf309d-43a6-44a3-abb8-266b50f869bd"},"source":["net= one_layer_net(2, 2) # complete here\n","print(net)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["one_layer_net(\n","  (mylayer): Linear(in_features=2, out_features=2, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b1VRqGxvN8Tc"},"source":["### Make a vector $x=\\begin{bmatrix}1\\\\1 \\end{bmatrix}$ and feed it to the network. What is the output probability? Check that it sums to one."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiVuevW6N8Tf","executionInfo":{"status":"ok","timestamp":1630078653602,"user_tz":-480,"elapsed":318,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"e96cd215-a7cf-4737-dbc1-334e83386226"},"source":["x= torch.ones(2) # complete here\n","print(x)\n","\n","# p = net.forward(x)\n","p = net(x) # complete here\n","print(p)\n","\n","print(p.sum() )"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([1., 1.])\n","tensor([0.6281, 0.3719], grad_fn=<SoftmaxBackward>)\n","tensor(1., grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RVM3COwzN8Th"},"source":["### Print the weights as well as the bias of the unique layer of this network. Be careful to use the correct name for this unique layer "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nU1pvUYzN8Tk","executionInfo":{"status":"ok","timestamp":1630079131029,"user_tz":-480,"elapsed":341,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"d10d0118-5f76-4076-8387-de589a0fb035"},"source":["print(net.mylayer.weight)\n","print(net.mylayer.bias)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([[-0.4473,  0.7004],\n","        [ 0.1986, -0.3029]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.1120, -0.2787], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WxWzt0e1N8Tl"},"source":["### Change the internal parameters of your network so that the weights are now equal to $\n","W=\\begin{bmatrix}\n","1&2 \\\\ 3&4 \n","\\end{bmatrix}\n","$ and the bias is equal to  $\n","b=\\begin{bmatrix}\n","1 \\\\ 1 \n","\\end{bmatrix}\n","$ "]},{"cell_type":"code","metadata":{"id":"KrkNKA0PN8Tm"},"source":["with torch.no_grad():\n","    # CHANGE THE WEIGHTS\n","    # complete here\n","    # complete here\n","    # complete here\n","    # complete here\n","\n","    # CHANGE THE BIAS\n","    # complete here\n","    # complete here\n","\n","    print(net.mylayer.weight)\n","    print(net.mylayer.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DYe6AOjCN8Tn"},"source":["### Feed the vector x to your network with updated parameters. What is the output? (you should get p= [2% 98%])"]},{"cell_type":"code","metadata":{"id":"nm4VVK3cN8Tn"},"source":["p= # complete here\n","print(p)"],"execution_count":null,"outputs":[]}]}