{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"vanilla_nn_demo.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"iV4zt1ffHnd8"},"source":["# Lab 03 : Vanilla neural networks -- demo\n","\n","# Creating a two-layer network"]},{"cell_type":"code","metadata":{"id":"lv57ndKsHneB","executionInfo":{"status":"ok","timestamp":1630076683266,"user_tz":-480,"elapsed":4039,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}}},"source":["import torch\n","import torch.nn as nn"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XN_VbhDiHneC"},"source":["### In Pytorch, networks are defined as classes"]},{"cell_type":"code","metadata":{"id":"glmPTQvVHneD","executionInfo":{"status":"ok","timestamp":1630076687847,"user_tz":-480,"elapsed":318,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}}},"source":["class two_layer_net(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(two_layer_net , self).__init__()\n","        \n","        self.layer1 = nn.Linear( input_size, hidden_size , bias=True)\n","        self.layer2 = nn.Linear( hidden_size, output_size , bias=True)        \n","        \n","    def forward(self, x):\n","        \n","        x = self.layer1(x)\n","        x = torch.relu(x)\n","        x = self.layer2(x)\n","        p = torch.softmax(x, dim=0)\n","        \n","        return p"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yh09fuIeHneD"},"source":["### Create an instance that takes input of size 2, then transform it into something of size 5, then into something of size 3\n","$$\n","\\begin{bmatrix}\n","\\times \\\\ \\times \n","\\end{bmatrix}\n","\\longrightarrow\n","\\begin{bmatrix}\n","\\times \\\\ \\times \\\\ \\times \\\\ \\times \\\\ \\times\n","\\end{bmatrix}\n","\\longrightarrow\n","\\begin{bmatrix}\n","\\times \\\\ \\times \\\\ \\times\n","\\end{bmatrix}\n","$$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APeqMsEiHneE","executionInfo":{"status":"ok","timestamp":1630076694897,"user_tz":-480,"elapsed":357,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"2689e8d3-ac0f-4f96-8beb-0c41345dcc74"},"source":["net= two_layer_net(2,5,3)\n","print(net)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["two_layer_net(\n","  (layer1): Linear(in_features=2, out_features=5, bias=True)\n","  (layer2): Linear(in_features=5, out_features=3, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OB_pI0sLHneF"},"source":["### Now we are going to make an input vector and feed it to the network:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UQRDBR8HneG","executionInfo":{"status":"ok","timestamp":1630076739497,"user_tz":-480,"elapsed":410,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"b9660009-a26d-491a-c9ca-73c1672cc86a"},"source":["x=torch.Tensor([1,1])\n","print(x)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor([1., 1.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NARI8kn7HneH","executionInfo":{"status":"ok","timestamp":1630076751691,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"882bc65e-4073-4210-8aad-715664cc62b1"},"source":["p=net.forward(x)\n","print(p)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor([0.3405, 0.2511, 0.4084], grad_fn=<SoftmaxBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tx9OTxW8HneI"},"source":["### Syntactic easy for the forward method"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3Zn9pxYHneJ","executionInfo":{"status":"ok","timestamp":1630076764571,"user_tz":-480,"elapsed":320,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"5b7f294b-32ef-40c7-eacd-f675d92f6b4b"},"source":["p=net(x)\n","print(p)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([0.3405, 0.2511, 0.4084], grad_fn=<SoftmaxBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9O66AvqUHneJ"},"source":["### Let's check that the probability vector indeed sum to 1:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OWPVuc1HneK","executionInfo":{"status":"ok","timestamp":1630076778213,"user_tz":-480,"elapsed":331,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"3a54aabb-f741-4615-d6d3-fafe8db93c8f"},"source":["print( p.sum() )"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor(1.0000, grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hxEOJF_tHneK"},"source":["### This network is composed of two Linear modules that we have called layer1 and layer2. We can see this when we type:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUWDzf66HneL","executionInfo":{"status":"ok","timestamp":1630076785735,"user_tz":-480,"elapsed":370,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"5945969b-d707-49d8-b326-495b97cd6fca"},"source":["print(net)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["two_layer_net(\n","  (layer1): Linear(in_features=2, out_features=5, bias=True)\n","  (layer2): Linear(in_features=5, out_features=3, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qRqBlEx2HneL"},"source":["### We can access the first module as follow:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5wg7D3HHneL","executionInfo":{"status":"ok","timestamp":1630076787984,"user_tz":-480,"elapsed":15,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"634e0260-880d-44ea-ee85-9df58921c79e"},"source":["print(net.layer1)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Linear(in_features=2, out_features=5, bias=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u3enZFg0HneM"},"source":["### To get the weights and bias of the first layer we do:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iR3R8c8jHneM","executionInfo":{"status":"ok","timestamp":1630076847739,"user_tz":-480,"elapsed":308,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"c318fa79-cc3d-4291-dbbd-25e410ab4cfc"},"source":["print(net.layer1.weight)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([[ 0.2512,  0.1420],\n","        [-0.5173,  0.3151],\n","        [ 0.1962, -0.5120],\n","        [-0.0039, -0.0420],\n","        [ 0.3137,  0.4086]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fs15qz6yHneM","executionInfo":{"status":"ok","timestamp":1630076852073,"user_tz":-480,"elapsed":323,"user":{"displayName":"Yirui Wang","photoUrl":"","userId":"14753845709256584186"}},"outputId":"94ea01d5-e18c-4af3-af09-369994d8cbf5"},"source":[" print(net.layer1.bias)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Parameter containing:\n","tensor([-0.0436,  0.3070,  0.5026, -0.0635,  0.1447], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PBNpOnslHneN"},"source":["### So to change the first row of the weights from layer 1 you would do:"]},{"cell_type":"code","metadata":{"id":"uP74F-69HneN","outputId":"e0f50eb0-ea4c-4faf-f62f-95d19d443582"},"source":["with torch.no_grad():\n","    net.layer1.weight[0,0]=10\n","    net.layer1.weight[0,1]=20\n","    print(net.layer1.weight)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[10.0000, 20.0000],\n","        [ 0.0500, -0.5119],\n","        [-0.1930, -0.1993],\n","        [-0.0208, -0.0490],\n","        [ 0.2011, -0.2519]], requires_grad=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"8bEuzw90HneN"},"source":["### Now we are going to feed  $x=\\begin{bmatrix}1\\\\1 \\end{bmatrix}$ to this modified network:"]},{"cell_type":"code","metadata":{"id":"4hdc7arcHneO","outputId":"a064602d-954a-437f-e5bc-6727065426be"},"source":["p=net(x)\n","print(p)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([9.5130e-01, 4.7772e-02, 9.2942e-04], grad_fn=<SoftmaxBackward>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"F8FEWMGcHneO"},"source":["### Alternatively, all the parameters of the network can be accessed by net.parameters(). "]},{"cell_type":"code","metadata":{"id":"btOOjpM-HneP","outputId":"6065820c-02d2-4d1b-b26e-368ccad88a0d"},"source":["list_of_param = list( net.parameters() )\n","print(list_of_param)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[Parameter containing:\n","tensor([[10.0000, 20.0000],\n","        [ 0.0500, -0.5119],\n","        [-0.1930, -0.1993],\n","        [-0.0208, -0.0490],\n","        [ 0.2011, -0.2519]], requires_grad=True), Parameter containing:\n","tensor([ 0.1292, -0.3313, -0.3548, -0.5247,  0.1753], requires_grad=True), Parameter containing:\n","tensor([[ 0.3178, -0.1838, -0.1930, -0.3816,  0.1850],\n","        [ 0.2342, -0.2743,  0.2424, -0.3598,  0.3090],\n","        [ 0.0876, -0.3785,  0.2032, -0.2937,  0.0382]], requires_grad=True), Parameter containing:\n","tensor([ 0.2120, -0.2751,  0.2351], requires_grad=True)]\n"]}]},{"cell_type":"code","metadata":{"id":"ZDD9ICyBHneP"},"source":[""],"execution_count":null,"outputs":[]}]}